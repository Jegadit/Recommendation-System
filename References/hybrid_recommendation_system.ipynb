{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDa4xEgkDxZy",
        "outputId": "70a521ab-a21d-4faa-d544-2b9a924bc49d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQkBmxFsD2W5",
        "outputId": "1468f297-07bc-4f0e-f21d-ba4fea29fb0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.7.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "from surprise import SVD, SVDpp, KNNBasic\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate,train_test_split, GridSearchCV\n",
        "from surprise import NormalPredictor\n",
        "from surprise import Reader\n",
        "import re \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk"
      ],
      "metadata": {
        "id": "DmBwWaIFDuqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "7Zjyto9yI0d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_cols = ['user_id', 'age', 'sex', 'occupation','zip_code']\n",
        "\n",
        "users = pd.read_csv(\"u.user\",sep=\"|\",names=u_cols,encoding=\"latin-1\")"
      ],
      "metadata": {
        "id": "xOjDrnp6n4jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.head()"
      ],
      "metadata": {
        "id": "avee0vsYqDfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i_cols = ['movie_id', 'title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
        " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
        " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "\n",
        "movies = pd.read_csv(\"u.item\",sep=\"|\",names=i_cols,encoding=\"latin-1\")"
      ],
      "metadata": {
        "id": "aurbOVfAqlOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.head(5)"
      ],
      "metadata": {
        "id": "1IMDZFobqyb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "\n",
        "ratings = pd.read_csv(\"u.data\",sep=\"\\t\",names=r_cols,encoding=\"latin-1\")"
      ],
      "metadata": {
        "id": "WORFrsc6rDHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head()"
      ],
      "metadata": {
        "id": "v0N5xodVrndf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratings.drop('timestamp', axis=1)"
      ],
      "metadata": {
        "id": "mo9uNZL4ryel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head(5)"
      ],
      "metadata": {
        "id": "XUf9ASVir33m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"X = ratings.copy()\n",
        "y = ratings['user_id']\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.20,random_state=42)\"\"\""
      ],
      "metadata": {
        "id": "iTr-uCp2r8Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_users = users.user_id.unique().shape[0]\n",
        "n_items = movies.movie_id.unique().shape[0]\n",
        "print('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))"
      ],
      "metadata": {
        "id": "xYepMuq7s10Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_arr = ratings[:]['rating'].unique()\n",
        "max_rating = np.amax(ratings_arr)\n",
        "min_rating = np.amin(ratings_arr)\n",
        "print(ratings_arr)"
      ],
      "metadata": {
        "id": "chIKFHrD_GI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_map = pd.Series(movies.movie_id.values,index=movies.title).to_dict()\n",
        "reverse_movie_map = {v: k for k, v in movie_map.items()}\n",
        "movieId_to_index_map = pd.Series(movies.index.values,index=movies.movie_id).to_dict()\n",
        "movieId_all_array = movies['movie_id'].unique()\n",
        "\n",
        "print(movie_map)\n",
        "print(movieId_all_array)"
      ],
      "metadata": {
        "id": "iu1dQsq_AfMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movieId( movie_name ):\n",
        "    \"\"\"\n",
        "    return the movieId which is corresponding to the movie name\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    movie_name: string, the name of the movie w/ or w/o the year\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    the movieId\n",
        "    \"\"\"\n",
        "\n",
        "    # If luckily the movie name is 100% equal to a name writen in the database,\n",
        "    # then return the id corresponding to the name.\n",
        "    # Or...we need to consider the similarity between strings \n",
        "    if (movie_name in movie_map):\n",
        "      return movie_map[movie_name]\n",
        "    else:\n",
        "      similar = []\n",
        "      for title, movie_id in movie_map.items():\n",
        "        ratio = fuzz.ratio(title.lower(), movie_name.lower())\n",
        "        if ( ratio >= 60):\n",
        "          similar.append( (title, movie_id, ratio ) )\n",
        "      if (len(similar) == 0):\n",
        "        print(\"Oh! This movie does not exist in the database.\")\n",
        "      else:\n",
        "        match_item = sorted( similar , key=lambda x: x[2] )[::-1]\n",
        "        print( \"The matched item might be:\", match_item[0][0], \", ratio=\",match_item[0][2] )\n",
        "        return match_item[0][1]"
      ],
      "metadata": {
        "id": "UhS7D1s9DKMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*content based filtering*"
      ],
      "metadata": {
        "id": "X_7Dq9DOE-H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "  torkenized = [PorterStemmer().stem(word).lower() for word in text.split('|') if word not in stopwords.words('english')]\n",
        "  return torkenized"
      ],
      "metadata": {
        "id": "ca7Iq9yAEYb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfid=TfidfVectorizer(analyzer='word', tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "TVogJgP0E6P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_g = movies['Action'].astype(str)+movies['Adventure'].astype(str)+movies['Animation'].astype(str)+movies['Children\\'s'].astype(str)+movies['Comedy'].astype(str)+movies['Crime'].astype(str)+movies['Documentary'].astype(str)+movies['Drama'].astype(str)+movies['Fantasy'].astype(str)+movies['Film-Noir'].astype(str)+movies['Horror'].astype(str)+movies['Musical'].astype(str)+movies['Mystery'].astype(str)+movies['Romance'].astype(str)+movies['Sci-Fi'].astype(str)+movies['Thriller'].astype(str)+movies['War'].astype(str)+movies['Western'].astype(str)"
      ],
      "metadata": {
        "id": "T7FHtAVjGVyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix = tfid.fit_transform(movie_g)"
      ],
      "metadata": {
        "id": "nNFY4vipE9uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim = cosine_similarity(tfidf_matrix,tfidf_matrix)"
      ],
      "metadata": {
        "id": "TFbbYmpzI6Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidf_matrix.shape)\n",
        "print(cos_sim.shape)\n",
        "print(movies.shape)"
      ],
      "metadata": {
        "id": "kpbhWaKmI_9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Collabrative filtering*"
      ],
      "metadata": {
        "id": "oosDdxsPJTSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['user_id','movie_id', 'rating']\n",
        "reader = Reader(rating_scale=(min_rating, max_rating))\n",
        "data = Dataset.load_from_df(ratings[features], reader)\n",
        "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
        "              'reg_all': [0.4, 0.6]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)"
      ],
      "metadata": {
        "id": "qw5haoRbJDDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs.fit(data)"
      ],
      "metadata": {
        "id": "ZEfiZDBhSvEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gs.best_score['rmse'])\n",
        "print(gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "c066uYr_S4Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = gs.best_params['rmse']\n",
        "model_svd = gs.best_estimator['rmse']\n",
        "model_svd.fit(data.build_full_trainset())"
      ],
      "metadata": {
        "id": "OqKel0oPTGqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rating_from_prediction( prediction, ratings_array ):\n",
        "    \"\"\"\n",
        "    return the closest rating number to the prediction value\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    prediction: float, the prediction value from the model\n",
        "\n",
        "    ratings_array: the 1D array of the discrete rating number\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    the rating number corresponding to the prediction value\n",
        "    \"\"\"\n",
        "    rating = ratings_array[ np.argmin( [ np.abs(item - prediction) for item in ratings_array ] ) ]\n",
        "    return rating"
      ],
      "metadata": {
        "id": "XY_8YKR6UtAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model_svd.predict(1,1)\n",
        "print(\"rating\", ratings[(ratings.user_id ==1 ) & (ratings.movie_id ==1 )]['rating'])\n",
        "print(\"prediction\",prediction.est)"
      ],
      "metadata": {
        "id": "WhyL0QuBUv8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "item based recommendation\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vHrDf7liVTEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_recommendation_item_based( similarity_matrix ,movieId_all_array, ratings_data, id_to_movie_map, movieId_to_index_map, fav_movie_list, n_recommendations, userId=-99):\n",
        "    \"\"\"\n",
        "    return top n movie recommendation based on user's input list of favorite movies\n",
        "    Currently, fav_movie_list only support one input favorate movie\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    similarity_matrix: 2d array, the pairwise similarity matrix\n",
        "\n",
        "    movieId_all_array: 1d array, the array of all movie Id\n",
        "\n",
        "    ratings_data: ratings data\n",
        "\n",
        "    id_to_movie_map: the map from movieId to movie title\n",
        "\n",
        "    movieId_to_index_map: the map from movieId to the index of the movie dataframe\n",
        "\n",
        "    fav_movie_list: list, user's list of favorite movies\n",
        "\n",
        "    n_recommendations: int, top n recommendations\n",
        "\n",
        "    userId: int optional (default=-99), the user Id\n",
        "            if userId = -99, the new user will be created\n",
        "            if userId = -1, the latest inserted user is chosen\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    list of top n movie recommendations\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if (userId == -99):\n",
        "      userId = np.amax( ratings_data['user_id'].unique() ) + 1\n",
        "    elif (userId == -1):\n",
        "      userId = np.amax( ratings_data['user_id'].unique() )\n",
        "\n",
        "    movieId_list = []\n",
        "    for movie_name in fav_movie_list:\n",
        "      movieId_list.append( get_movieId(movie_name) )    \n",
        "\n",
        "    # Get the movie id which corresponding to the movie the user didn't watch before\n",
        "    movieId_user_exist = list( ratings_data[ ratings_data.user_id==userId ]['movie_id'].unique() )\n",
        "    movieId_user_exist = movieId_user_exist + movieId_list\n",
        "    movieId_input = []\n",
        "    for movieId in movieId_all_array:\n",
        "      if (movieId not in movieId_user_exist):\n",
        "         movieId_input.append( movieId )\n",
        "\n",
        "    print(movieId_list[0])\n",
        "    index = movieId_to_index_map[movieId_list[0]]\n",
        "    cos_sim_scores=list(enumerate(similarity_matrix[index]))\n",
        "    cos_sim_scores=sorted(cos_sim_scores,key=lambda x:x[1],reverse=True) \n",
        "  \n",
        "    topn_movieIndex = []\n",
        "    icount = 0\n",
        "    for i in range(len(cos_sim_scores)):\n",
        "      if( cos_sim_scores[i][0] in [movieId_to_index_map[ids] for ids in movieId_input ]  ):\n",
        "        icount += 1\n",
        "        topn_movieIndex.append( cos_sim_scores[i][0] )\n",
        "        if( icount == n_recommendations ):\n",
        "          break\n",
        "    \n",
        "    topn_movie = [ movies.loc[index].title for index in topn_movieIndex ]\n",
        "    return topn_movie"
      ],
      "metadata": {
        "id": "2qm2mPs3U8zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "#user based recommendation\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "29AWpb2gV37_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_recommendation_user_based(best_model_params, movieId_all_array, ratings_data, id_to_movie_map,\n",
        "                        fav_movie_list, n_recommendations, userId=-99 ):\n",
        "    \"\"\"\n",
        "    return top n movie recommendation based on user's input list of favorite movies\n",
        "    Currently, fav_movie_list only support one input favorate movie\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    best_model_params: dict, {'iterations': iter, 'rank': rank, 'lambda_': reg}\n",
        "\n",
        "    movieId_all_array: the array of all movie Id\n",
        "\n",
        "    ratings_data: ratings data\n",
        "\n",
        "    id_to_movie_map: the map from movieId to movie title\n",
        "\n",
        "    fav_movie_list: list, user's list of favorite movies\n",
        "\n",
        "    n_recommendations: int, top n recommendations\n",
        "\n",
        "    userId: int optional (default=-99), the user Id\n",
        "            if userId = -99, the new user will be created\n",
        "            if userId = -1, the latest inserted user is chosen\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    list of top n movie recommendations\n",
        "    \"\"\"\n",
        "\n",
        "    movieId_list = []\n",
        "    for movie_name in fav_movie_list:\n",
        "      movieId_list.append( get_movieId(movie_name) )\n",
        "\n",
        "    if (userId == -99):\n",
        "      userId = np.amax( ratings_data['user_id'].unique() ) + 1\n",
        "    elif (userId == -1):\n",
        "      userId = np.amax( ratings_data['user_id'].unique() )\n",
        "\n",
        "    ratings_array = ratings['rating'].unique()\n",
        "    max_rating = np.amax( ratings_array )\n",
        "    min_rating = np.amin( ratings_array )\n",
        "    \n",
        "    # create the new row which corresponding to the input data\n",
        "    user_rows = [[userId, movieId, max_rating] for movieId in movieId_list]\n",
        "    df = pd.DataFrame(user_rows, columns =['user_id', 'movie_id', 'rating']) \n",
        "    train_data = pd.concat([ratings_data, df], ignore_index=True, sort=False)\n",
        "\n",
        "    # Get the movie id which corresponding to the movie the user didn't watch before\n",
        "    movieId_user_exist = train_data[ train_data.user_id==userId ]['movie_id'].unique()\n",
        "    movieId_input = []\n",
        "    for movieId in movieId_all_array:\n",
        "      if (movieId not in movieId_user_exist):\n",
        "         movieId_input.append( movieId )\n",
        "\n",
        "    reader = Reader(rating_scale=(min_rating, max_rating))\n",
        "\n",
        "    data = Dataset.load_from_df(train_data, reader)\n",
        "\n",
        "    model = SVD(**best_model_params)\n",
        "    model.fit(data.build_full_trainset())\n",
        "\n",
        "    predictions = []\n",
        "    for movieId in movieId_input:\n",
        "      predictions.append( model.predict(userId,movieId) )\n",
        "\n",
        "    \n",
        "    sort_index = sorted(range(len(predictions)), key=lambda k: predictions[k].est, reverse=True)\n",
        "    topn_predictions = [ predictions[i].est for i in sort_index[0:min(n_recommendations,len(predictions))] ]\n",
        "    topn_movieIds = [ movieId_input[i] for i in sort_index[0:min(n_recommendations,len(predictions))] ]\n",
        "    topn_rating = [ get_rating_from_prediction( pre, ratings_array ) for pre in topn_predictions ]\n",
        "\n",
        "    topn_movie = [ id_to_movie_map[ ids ] for ids in topn_movieIds ]\n",
        "    return topn_movie"
      ],
      "metadata": {
        "id": "jjZ971UTVyc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_favorite_movies = ['Iron Man']\n",
        "\n",
        "# get recommends\n",
        "n_recommendations = 10\n",
        "\n",
        "recommends_item_based = make_recommendation_item_based( \n",
        "    similarity_matrix = cos_sim,\n",
        "    movieId_all_array = movieId_all_array,\n",
        "    ratings_data = ratings[features], \n",
        "    id_to_movie_map = reverse_movie_map, \n",
        "    movieId_to_index_map = movieId_to_index_map,\n",
        "    fav_movie_list = my_favorite_movies, \n",
        "    n_recommendations = n_recommendations)\n",
        "\n",
        "recommends_user_based = make_recommendation_user_based(\n",
        "    best_model_params = best_params, \n",
        "    movieId_all_array = movieId_all_array,\n",
        "    ratings_data = ratings[features], \n",
        "    id_to_movie_map = reverse_movie_map, \n",
        "    fav_movie_list = my_favorite_movies, \n",
        "    n_recommendations = n_recommendations)\n",
        "\n",
        "print(\"-------------Search based on item's content similarity--------------------\")\n",
        "print('The movies similar to' , my_favorite_movies , ':' )\n",
        "for i, title in enumerate(recommends_item_based):\n",
        "    print(i+1, title)  \n",
        "if( len(recommends_item_based) < n_recommendations ):\n",
        "  print(\"Sadly, we couldn't offer so many recommendations :(\")    \n",
        "\n",
        "print(\"--------------Search based on similarity between user's preference--------------------------------------\")\n",
        "print('The users like' , my_favorite_movies , 'also like:')\n",
        "for i, title in enumerate(recommends_user_based):\n",
        "    print(i+1, title)\n",
        "if( len(recommends_user_based) < n_recommendations ):\n",
        "  print(\"Sadly, we couldn't offer so many recommendations :(\")\n"
      ],
      "metadata": {
        "id": "-bbt5g-JWO4q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}